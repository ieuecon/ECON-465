---
title: "Text Mining"
subtitle: "Lecture 4"
author:
    - Ayla Oğuş Binatlı
date: 11/02/2023
editor: visual
format:
  revealjs: 
    auto-animate-easing: ease-in-out
    auto-animate-unmatched: false
    auto-animate-duration: 0.4
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    output-location: fragment
    transition: none
    width: 1600
    height: 900
    code-overflow: wrap
    css: styles.css
editor_options: 
  chunk_output_type: console
---

## Packages

First things first: we need to load the necessary libraries

```{r}
#| code-overflow: wrap
#| echo: true
#| eval: true
#| code-line-numbers: "2-5"
suppressPackageStartupMessages({
  library(tidyverse) # data wrangling
  library(lubridate) # working with dates
  library(scales) # axis values to percentage
  library(dslabs) # the data
})

```

::: fragment

::: {style="font-size: 0.75em"}

During the 2016 US presidential election, then candidate Donald J. Trump used his twitter account as a way to communicate with potential voters.

<br>

On August 6, 2016, Todd Vaziri tweeted1 about Trump that "Every non-hyperbolic tweet is from iPhone (his staff). Every hyperbolic tweet is from Android (from him)."

<br>

Data scientist David Robinson conducted an analysis to determine if data supported this assertion. Here, we go through David's analysis to learn some of the basics of text mining.

:::
:::

## Text Mining

### Case Study: Trump Tweets
::: fragment
::: {style="font-size: 0.75em"}
We are going to use the data frame called `trump_tweets`.

You can download tweets from twitter using `rtweet` package. But we will use an already compiled data set.

See what `trump_tweets` looks like.
:::
:::
::: fragment
```{r}
#| echo: true
#| eval: true
head(trump_tweets) |> as_tibble()
```
:::

::: fragment
```{r}
#| echo: true
#| eval: true
trump_tweets$text[16413]
```
:::

## Text Mining

### Case Study: Trump Tweets

How many tweets are there?

Let's look at tweets by source:

::: fragment
```{r}
#| echo: true
#| eval: true
trump_tweets |> 
  count(source) |>
  arrange(desc(n)) |>
  head(5)
```
:::

## Text Mining

### Case Study: Trump Tweets

::: fragment
We are interested in what happened during the campaign:

```{r}
#| echo: true
#| eval: true
#| code-line-numbers: "1-2|3-5|6-8|9"
campaign_tweets <- trump_tweets |> 
  extract(source, "source", "Twitter for (.*)") |>
  filter(source %in% c("Android", "iPhone") & 
           created_at >=ymd("2015-06-17") &
           created_at < ymd("2016-11-08")) |>
  filter(!is_retweet) |> 
  arrange(created_at) |>
  as_tibble()
campaign_tweets
```
:::

## Text Mining

### Case Study: Trump Tweets

::: fragment
We are interested in what happened during the campaign:

```{r}
#| echo: true
#| eval: true
#| output-location: slide
#| fig-align: center
campaign_tweets |>
  mutate(hour = hour(with_tz(created_at, "EST"))) |>
  count(source, hour) |>
  group_by(source) |>
  mutate(percent = n / sum(n)) |>
  ungroup() |>
  ggplot(aes(hour, percent, color = source)) + 
  geom_line() +
  geom_point() +
  scale_y_continuous(labels = percent_format()) + 
  labs(x = "Hour of day (EST", y = "% of tweets", color ="") + theme_light()
```
:::

## Text Mining

### Case Study: Trump Tweets

::: fragment
The tidytext package helps us convert free form text into a tidy table. In this package text is broken down into tokens and then tokens are analyzed. Here is a simple example:

```{r}
#| echo: true
#| eval: false
install.packages("tidytext")
```
:::

::: fragment
```{r}
#| echo: true
#| eval: true
library(tidytext)
poem <- c("Roses are red,", "Violets are blue,", 
          "Sugar is sweet,", "And so are you.")
example <- tibble(line = c(1, 2, 3, 4),
                      text = poem)
```
:::

## Text Mining

### Case Study: Trump Tweets

::: fragment
What does "example" look like ?

We make a table of words. Here the table is of lines of a poem.
:::

::: fragment
```{r}
#| echo: true
#| eval: true
example
```
:::

## Text Mining

### Case Study: Trump Tweets

We will next break the lines down into words.

::: fragment
```{r}
#| echo: true
#| eval: true
example |> unnest_tokens(word, text)
```
:::

## Text Mining

### Case Study: Trump Tweets

::: fragment
Now let's look at an example from the tweets.

```{r}
#| echo: true
#| eval: true
i <- 3008
campaign_tweets$text[i] |> str_wrap(width = 65) |> cat()
```
:::

::: fragment
```{r}
#| echo: true
#| eval: true
campaign_tweets[i,] |> 
  unnest_tokens(word, text) |>
  pull(word) 
```
:::

## Text Mining

### Case Study: Trump Tweets

::: fragment
Let's remove some garbage.

```{r}
#| echo: true
#| eval: true
links <- "https://t.co/[A-Za-z\\d]+|&amp;"
campaign_tweets[i,] |> 
  mutate(text = str_replace_all(text, links, ""))  |>
  unnest_tokens(word, text) |>
  pull(word)
```
:::

## Text Mining

### Case Study: Trump Tweets

::: fragment
Now we are ready to extract the words for all our tweets.

```{r}
#| echo: true
#| eval: true
tweet_words <- campaign_tweets |> 
  mutate(text = str_replace_all(text, links, ""))  |>
  unnest_tokens(word, text)
tweet_words
```
:::

## Text Mining

### Case Study: Trump Tweets

::: fragment
Let ' s look at the most common words .
:::

::: fragment
```{r}
#| echo: true
#| eval: true
tweet_words |> 
  count(word) |>
  arrange(desc(n))
```
:::

::: fragment
Not surprising . Totally uninformative .
:::

## Text Mining

### Case Study: Trump Tweets

::: fragment
`stop_words` has the most common words in the English language so we can ignore these.

```{r}
#| echo: true
#| eval: true
stop_words
```
:::

## Text Mining {.scrollable}

### Case Study: Trump Tweets

::: fragment
::: {style="font-size: 0.75em"}
If we filter out rows representing stop words with `filter(!word %in% stop_words$word)`:
:::
:::

::: fragment
```{r}
#| echo: true
#| eval: true
#| code-line-numbers: "1|2-4"
tweet_words <- campaign_tweets |> 
  mutate(text = str_replace_all(text, links, ""))  |>
  unnest_tokens(word, text) |>
  filter(!word %in% stop_words$word ) 

```
:::

::: fragment
::: {style="font-size: 0.75em"}
We end up with a much more informative set of top 10 tweeted words:
:::
:::

::: fragment
```{r}
#| echo: true
#| eval: true
#| code-line-numbers: "1|2-5"
tweet_words |> 
  count(word) |>
  top_n(10, n) |>
  mutate(word = reorder(word, n)) |>
  arrange(desc(n)) 
```
:::

## Text Mining {.scrollable}

### Case Study: Trump Tweets

::: fragment
::: {style="font-size: 0.75em"}

These are a lot more informative.
But still if we look at the word list, there are uninformative words. For example dates. Also unwanted characters like `’` attached to a word.
It was the first word in a quote. Let’s remove these.
:::
```{r}
#| echo: true
#| eval: true
#| code-line-numbers: "1|2-6"
tweet_words <- campaign_tweets |> 
  mutate(text = str_replace_all(text, links, ""))  |>
  unnest_tokens(word, text) |>
  filter(!word %in% stop_words$word &
           !str_detect(word, "^\\d+$")) |>
  mutate(word = str_replace(word, "^'", ""))
```
:::


::: fragment
::: {style="font-size: 0.75em"}

Now let’s compare the most used words in tweets from Android or iphone.
:::
```{r}
#| echo: true
#| eval: true
#| code-line-numbers: "1|2-5"
android_vs_iphone <- tweet_words |>
  count(word, source) |>
  pivot_wider(names_from = "source", values_from = "n", values_fill = 0) |>
  mutate(p_a = Android / sum(Android), p_i = iPhone / sum(iPhone),
         percent_diff = (p_a - p_i) / ((p_a + p_i)/2) * 100)
```


:::

## Text Mining {.scrollable}

### Case Study: Trump Tweets

::: fragment

For words appearing at least 100 times in total, here are the highest percent differences;

:::
::: fragment
:::: {.columns}

::: {.column width="47%"}
::: {style="font-size: 0.85em"}
Android:


```{r}
#| echo: true
#| eval: true
android_vs_iphone |> filter(Android + iPhone >= 100) |>
  arrange(desc(percent_diff))
```
:::
:::



::: {.column width="53%"}
::: {style="font-size: 0.85em"}

iPhone:

```{r}
#| echo: true
#| eval: true

android_vs_iphone |> filter(Android + iPhone >= 100) |> 
  arrange(percent_diff)
```
:::
:::
::::
:::

## Text Mining {.scrollable}

### Case Study: Trump Tweets

::: fragment
::: {style="font-size: 0.75em"}

Some words reflect negative or positive sentiments.

:::
:::

::: fragment


```{r}
#| echo: true
#| eval: false
install.packages('tidytext')
install.packages('textdata')
```


:::

::: fragment


```{r}
#| echo: true
#| eval: true
library(tidytext)
library(textdata)
```


:::

## Text Mining {.scrollable}
### Case Study: Trump Tweets

::: fragment
:::: {.columns}

::: {.column width="50%"}
```{r}
#| echo: true
#| eval: true
get_sentiments("bing")
```
:::

::: {.column width="50%"}
```{r}
#| echo: true
#| eval: true
get_sentiments("afinn")
```
:::
::::
:::

## Text Mining {.scrollable}
### Case Study: Trump Tweets

::: fragment
:::: {.columns}

::: {.column width="50%"}
```{r}
#| echo: true
#| eval: true
get_sentiments("loughran") |> count(sentiment)
```
:::

::: {.column width="50%"}
```{r}
#| echo: true
#| eval: true
get_sentiments("nrc") |> count(sentiment)
```
:::
::::
:::

## Text Mining {.scrollable}

### Case Study: Trump Tweets

::: fragment

For our analysis, we are interested in exploring the different sentiments of each tweet so we will use the `nrc` lexicon:

:::
::: fragment

```{r}
#| echo: true
#| eval: true
nrc <- get_sentiments("nrc") |>
  select(word, sentiment)
```

:::
::: fragment

We will only keep words associated with a sentiment in the tweets.

:::

::: fragment

```{r}
#| echo: true
#| eval: true
tweet_words |> inner_join(nrc, by = "word", relationship = "many-to-many") |> 
  select(source, word, sentiment) |> 
  sample_n(5)
```

:::

## Text Mining {.scrollable}

### Case Study: Trump Tweets

::: fragment

Then count them:

:::
::: fragment

```{r}
#| echo: true
#| eval: true
sentiment_counts <- tweet_words |>
  left_join(nrc, by = "word", relationship = "many-to-many") |>
  count(source, sentiment) |>
  pivot_wider(names_from = "source", values_from = "n") |>
  mutate(sentiment = replace_na(sentiment, replace = "none"))
sentiment_counts
```

:::

## Text Mining {.scrollable}

### Case Study: Trump Tweets

::: fragment

Compare the different sentiments in the tweets from different sources.

:::

::: fragment

```{r}
#| echo: true
#| eval: true
sentiment_counts |>
  mutate(p_a = Android / sum(Android) , 
         p_i = iPhone / sum(iPhone), 
         percent_diff = (p_a - p_i) / ((p_a + p_i)/2) * 100) |>
  arrange(desc(percent_diff))
```

:::

