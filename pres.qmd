---
title: "Text Mining"
subtitle: "Lecture 4"
author:
    - Ayla Oğuş Binatlı
date: 11/02/2023
editor: visual
format:
  revealjs: 
    auto-animate-easing: ease-in-out
    auto-animate-unmatched: false
    auto-animate-duration: 0.4
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    output-location: fragment
    transition: none
    width: 1600
    height: 900
    code-overflow: wrap
    css: styles.css
editor_options: 
  chunk_output_type: console
---

## Packages

First things first: we need to load the necessary libraries

```{r}
#| code-overflow: wrap
#| echo: true
#| eval: true
#| code-line-numbers: "2-5"
suppressPackageStartupMessages({
  library(tidyverse) # data wrangling
  library(lubridate) # working with dates
  library(scales) # axis values to percentage
  library(dslabs) # the data
})

```

## Text Mining
### Case Study: Trump Tweets

During the 2016 US presidential election, then candidate Donald J. Trump used his twitter account as a way to communicate with potential voters.

On August 6, 2016, Todd Vaziri tweeted1 about Trump that “Every non-hyperbolic tweet is from iPhone (his staff). Every hyperbolic tweet is from Android (from him).” 

Data scientist David Robinson conducted an analysis to determine if data supported this assertion. Here, we go through David’s analysis to learn some of the basics of text mining.

## Text Mining 
### Case Study: Trump Tweets

We are going to use the data frame called `trump_tweets`.

You can download tweets from twitter using `rtweet` package. But we will use an already compiled data set.

See what `trump_tweets` looks like.

::: {.fragment}

```{r}
#| echo: true
#| eval: true
head(trump_tweets) |> as_tibble()
```
::: 

## Text Mining
### Case Study: Trump Tweets
::: {.fragment}

```{r}
#| echo: true
#| eval: true
trump_tweets$text[16413]
```
::: 


## Text Mining
### Case Study: Trump Tweets

How many tweets are there?

Let's look at tweets by source:

::: {.fragment}

```{r}
#| echo: true
#| eval: true
trump_tweets |> 
  count(source) |>
  arrange(desc(n)) |>
  head(5)
```
::: 


## Text Mining
### Case Study: Trump Tweets
::: {.fragment}
We are interested in what happened during the campaign: 
```{r}
#| echo: true
#| eval: true
#| code-line-numbers: "1-2|3-5|6|7|8|9"
campaign_tweets <- trump_tweets |> 
  extract(source, "source", "Twitter for (.*)") |>
  filter(source %in% c("Android", "iPhone") & 
           created_at >=ymd("2015-06-17") &
           created_at < ymd("2016-11-08")) |>
  filter(!is_retweet) |> 
  arrange(created_at) |>
  as_tibble()
campaign_tweets
```
::: 

## Text Mining
### Case Study: Trump Tweets

::: {.fragment}
We are interested in what happened during the campaign: 
```{r}
#| echo: true
#| eval: true
#| output-location: slide
#| fig-align: center
campaign_tweets |>
  mutate(hour = hour(with_tz(created_at, "EST"))) |>
  count(source, hour) |>
  group_by(source) |>
  mutate(percent = n / sum(n)) |>
  ungroup() |>
  ggplot(aes(hour, percent, color = source)) + 
  geom_line() +
  geom_point() +
  scale_y_continuous(labels = percent_format()) + 
  labs(x = "Hour of day (EST", y = "% of tweets", color ="") + theme_light()
```
::: 

## Text Mining
### Case Study: Trump Tweets

::: {.fragment}
The tidytext package helps us convert free form text into a tidy table.
In this package text is broken down into tokens and then tokens are analyzed.
Here is a simple example:

```{r}
#| echo: true
#| eval: false
install.packages("tidytext")
```
:::

::: {.fragment}
```{r}
#| echo: true
#| eval: true
library(tidytext)
poem <- c("Roses are red,", "Violets are blue,", 
          "Sugar is sweet,", "And so are you.")
example <- tibble(line = c(1, 2, 3, 4),
                      text = poem)
```
::: 

## Text Mining
### Case Study: Trump Tweets

::: {.fragment}
What does ”example” look like ?

We make a table of words. Here the table is of lines of a poem. 
:::

::: {.fragment}

```{r}
#| echo: true
#| eval: true
example
```
::: 

## Text Mining
### Case Study: Trump Tweets
We will next break the lines down into words.

::: {.fragment}
```{r}
#| echo: true
#| eval: true
example |> unnest_tokens(word, text)
```
::: 

## Text Mining
### Case Study: Trump Tweets

::: {.fragment}

Now let’s look at an example from the tweets. 

```{r}
#| echo: true
#| eval: true
i <- 3008
campaign_tweets$text[i] |> str_wrap(width = 65) |> cat()
```


```{r}
#| echo: true
#| eval: true
campaign_tweets[i,] |> 
  unnest_tokens(word, text) |>
  pull(word) 
```

::: 


## Text Mining
### Case Study: Trump Tweets

::: {.fragment}

Let's remove some garbage.

```{r}
#| echo: true
#| eval: true
links <- "https://t.co/[A-Za-z\\d]+|&amp;"
campaign_tweets[i,] |> 
  mutate(text = str_replace_all(text, links, ""))  |>
  unnest_tokens(word, text) |>
  pull(word)
```

:::

## Text Mining
### Case Study: Trump Tweets

::: {.fragment}
Now we are ready to extract the words for all our tweets.

```{r}
#| echo: true
#| eval: true
tweet_words <- campaign_tweets |> 
  mutate(text = str_replace_all(text, links, ""))  |>
  unnest_tokens(word, text)
tweet_words
```

:::

## Text Mining
### Case Study: Trump Tweets

::: {.fragment}

Let ’ s look at the most common words .

:::

::: {.fragment}

```{r}
#| echo: true
#| eval: true
tweet_words |> 
  count(word) |>
  arrange(desc(n))
```
:::

::: {.fragment}

Not surprising . Totally uninformative .

:::

## Text Mining
### Case Study: Trump Tweets

::: {.fragment}

`stop_words` has the most common words in the English language so we can ignore these.

```{r}
#| echo: true
#| eval: true
stop_words
```

:::

## Text Mining {.scrollable}
### Case Study: Trump Tweets 

::: {.fragment}
::: {style="font-size: 0.7em"}

If we filter out rows representing stop words with
`filter(!word %in% stop_words$word)`:
:::

:::

::: {.fragment}

```{r}
#| echo: true
#| eval: true
tweet_words <- campaign_tweets |> 
  mutate(text = str_replace_all(text, links, ""))  |>
  unnest_tokens(word, text) |>
  filter(!word %in% stop_words$word ) 

```

:::
::: {.fragment}
::: {style="font-size: 0.6em"}
We end up with a much more informative set of top 10 tweeted words:
:::
:::
::: {.fragment}

```{r}
#| echo: true
#| eval: true
tweet_words |> 
  count(word) |>
  top_n(10, n) |>
  mutate(word = reorder(word, n)) |>
  arrange(desc(n)) 
```

:::
































